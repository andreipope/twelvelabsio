---
title: "Providing Transcriptions From the Local File System"
---

In this guide you'll learn how to upload a video and provide a transcription when both files reside on the local file system.

Note that, although the example code in this guide is written in [Python](https://www.python.org) and [Node.js](https://nodejs.org/en/), the API is compatible with most programming languages, and you can also use [Postman](https://www.postman.com) or other REST clients to send requests and view responses.

## Prerequisites

- Your transcription must be in the SRT or VTT format.

- Your video must meet the following requirements:

  - **Video resolution:** must be greater or equal than 360p and less than 1080p (FHD)
  - **Duration**: must be between 15 seconds and 2 hours (7,200s) If you require different options, send us an email at support\[at\]twelvelabs.io.

- You're familiar with the concepts that are described on the [Understand](/understand) page.

- You've already created an index. For details, see the [Create an Index](/reference/api-reference/indexes#create-an-index) section.

## Recommendations

- For consistent search results, Twelve Labs recommends you upload 360p videos.

## Procedure

1. Declare the [tasks endpoint](/reference/api-reference/indexes-tasks):

Python

Node.js

INDEX_TASK_URL \= f"{API_URL}/indexes/tasks"

const INDEX_TASK_URL \= \`${API_URL}/indexes/tasks\`

2. Read your video file. Open a stream, making sure to replace the placeholders surrounded by `<>` with your values.

Python

Node.js

video_file_path \= "<YOUR_VIDEO_FILE_PATH>"

video_file_name \= "<YOUR_VIDEO_FILE_NAME>"

video_file_stream \= open(video_file_path, "rb")

const video_file_path \= '<YOUR_VIDEO_FILE_PATH>'

const video_file_stream \= fs.createReadStream(video_file_path)

3. Read your transcription file. Open a stream, making sure to replace the placeholders surrounded by `<>` with your values:

Python

Node.js

transcription_file_path \= "<YOUR_TRANSCRIPTION_FILE_PATH>"

transcription_file_name \= "<YOUR_TRANSCRIPTION_FILE_NAME>"

transcription_file_stream \= open(transcription_file_path, "rb")

const transcription_file_path \= '<YOUR_TRANSCRIPTION_FILE_PATH>'

const transcription_file_stream \= fs.createReadStream(transcription_file_path)

4. To provide a transcription file, you must set the `provide_transcription` parameter to `true` and specify the index ID, the language of your video, and the video and transcription files:

Python

Node.js

Store the `provide_transcription` parameter, the index ID, and the language of your video in a dictionary named `data`. Then, store the video and transcription files in an array named `file_param`:

data \= {

"provide_transcription": True

"index_id": "<YOUR_INDEX_ID>",

"language": "en",

}

file_param \= \[

("video_file", (video_file_name, video_file_stream, "application/octet-stream")),

("transcription_file", (transcription_file_name, transcription_file_stream, "application/octet-stream")),

\]

Store all the required parameters in a variable named `formData` of type `FormData`:

let formData \= new FormData()

formData.append('provide_transcription', 'true')

formData.append('INDEX_ID', '<YOUR_INDEX_ID>')

formData.append('language', 'en')

formData.append('video_file', video_file_stream)

formData.append('transcription_file', transcription_file_stream)

5. Upload your video and transcription files. Call the [tasks endpoint](/reference/api-reference/indexes-tasks#creates-a-new-video-index-task) and store the result in a variable named `response`:

Python

Node.js

response \= requests.post(INDEX_TASK_URL, headers\=headers, data\=data, files\=file_param)

config \= {

method: 'post',

url: INDEX_TASK_URL,

headers: headers,

data : formData

};

resp \= await axios(config)

response \= await resp.data

6. Store the ID of your task in a variable named `TASK_ID` and print the status code and response:

Python

Node.js

TASK_ID \= response.json().get("\_id")

print (f"Status code: {response.status_code}")

pprint (response.json())

const TASK_ID \= response.\_id

console.log(\`Status code: ${resp.status}\`)

console.log(response)

The output should look similar to the following one:

Status code: 200

{'\_id': '626a229622c7851fcbe5c83b',

'message': 'Succesfully requested indexing task',

'type': 'index_task_create'}

7. _(Optional)_ You can use the [tasks/{\_id}](/reference/api-reference/indexes-tasks#get-the-status-info-of-the-video-index-task.) endpoint to monitor the indexing process. Wait until the status shows as `ready`:

Python

Node.js

INDEX_TASK_STATUS_URL \= f"{API_URL}/indexes/tasks/{TASK_ID}"

while True:

response \= requests.get(INDEX_TASK_STATUS_URL, headers\=headers)

STATUS \= response.json().get("status")

if STATUS \== "ready":

print (f"Status code: {STATUS}")

pprint (response.json())

break

time.sleep(10)

const INDEX_TASK_STATUS_URL \= \`${API\_URL}/indexes/tasks/${TASK_ID}\`

config \= {

method: 'get',

url: INDEX_TASK_STATUS_URL,

headers: headers,

}

let STATUS

do {

resp \= await axios(config)

response \= await resp.data

STATUS \= response.status

if (STATUS !== 'ready')

await new Promise(r \=> setTimeout(r, 10000));

} while (STATUS !== 'ready')

console.log(\`Status code: ${STATUS}\`)

console.log(response)

The output should look similar to the following one:

Status code: 200

{'\_id': '626a3ddc22c7851fcbe5c844',

'created_at': '2022-04-28T07:10:20.453Z',

'estimated_time': '2022-04-28T07:22:08.885Z',

'index_id': '626a273122c7851fcbe5c842',

'metadata': {'duration': 552.92,

'filename': 'car-accidents.mp4',

'height': 720,

'width': 1280},

'status': 'ready',

'type': 'index_task_info',

'updated_at': '2022-04-28T07:22:09.16Z'}

**NOTE**: For details about the possible statuses, see the [Indexes/Tasks](/reference/api-reference/indexes-tasks) page.

## Related Topics

- [Indexes/Tasks](/reference/api-reference/indexes-tasks)
