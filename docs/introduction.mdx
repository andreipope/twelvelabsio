---
title: "Introduction"
---

Twelve Labs Video Understanding API is an AI-powered video search solution that
extracts information such as movement, objects, sound, text on screen, and
speech from your videos and allows you to find specific moments using everyday
language.

## Why Use Twelve Labs Video Understanding API?

The following sections describe the key capabilities of Twelve Labs Video
Understanding API and compare it to other solutions.

### Key Capabilities

Developers using Twelve Labs Video Understanding API have access to the
following key capabilities:

- **Relevance**: Find the exact moment you need within your video library using
  a full text-based search query.

- **Intuitive:** Integrate more than twenty state-of-the-art deep learning
  models into your applications in three simple steps.

- **Speed:** Receive your search results within seconds.

- **Scalability:** With Twelve Labs, your applications rely on a cloud-native
  distributed infrastructure that can handle thousands of simultaneous indexing
  and search requests.

<Note>
  Twelve Labs is continuously adding new features. See the [Roadmap](/roadmap)
  page for details.
</Note>

### Twelve Labs Video Understanding API Compared to Other Solutions

The table below provides a basic comparison between Twelve Labs Video
Understanding API and other cloud-based solutions:

![](/images/twelve-labs-compared.png)

Twelve Labs Video Understand API compared to other solutions

- **Use a single API** to access Twelve Labs AI-powered video search service
  that allows you to find the information youâ€™re looking for in your videos.
  Focus on building your application instead of collating data from separate
  image and speech APIs.

- **Write complex semantic queries in everyday language** that semantically
  describe the exact moment you want to find in your videos instead of filtering
  pre-generated tags.

- **Adapt the AI model to your domain** instead of relying on a single model.
  Note that this feature is on the [roadmap](/roadmap).
